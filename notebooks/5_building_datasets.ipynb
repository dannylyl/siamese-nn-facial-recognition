{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Datasets For Model Training\n",
    "\n",
    "Carrying on from [Issue #6](https://github.com/dannylyl/siamese-nn-facial-recognition/issues/6), this issue will involve steps for building the datasets for further downstream steps in this project. This would include:\n",
    "\n",
    "1. Deciding Train Test Split Methodology and Implementation\n",
    "2. Building Positive (similar) and Negative (dissimilar) pairs and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting Pandas DF of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the notebook for issue #6, I will start by first organising the data into a pandas dataframe (personal preference I guess since I usually work with data in DFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/lfw-deepfunneled/lfw-deepfunneled'\n",
    "\n",
    "data = []\n",
    "\n",
    "for person in os.listdir(data_dir):\n",
    "    person_dir = os.path.join(data_dir, person)\n",
    "    if os.path.isdir(person_dir):\n",
    "        for image in os.listdir(person_dir):\n",
    "            data.append((os.path.join(person_dir, image), person))\n",
    "            \n",
    "df = pd.DataFrame(data, columns=['image_path', 'person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Alic...</td>\n",
       "      <td>Alice_Fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Alic...</td>\n",
       "      <td>Alice_Fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Elle...</td>\n",
       "      <td>Ellen_Barkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Quee...</td>\n",
       "      <td>Queen_Latifah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Quee...</td>\n",
       "      <td>Queen_Latifah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path         person\n",
       "0  ../data/lfw-deepfunneled/lfw-deepfunneled/Alic...   Alice_Fisher\n",
       "1  ../data/lfw-deepfunneled/lfw-deepfunneled/Alic...   Alice_Fisher\n",
       "2  ../data/lfw-deepfunneled/lfw-deepfunneled/Elle...   Ellen_Barkin\n",
       "3  ../data/lfw-deepfunneled/lfw-deepfunneled/Quee...  Queen_Latifah\n",
       "4  ../data/lfw-deepfunneled/lfw-deepfunneled/Quee...  Queen_Latifah"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Test Split Methodology\n",
    "\n",
    "As suggested from Issue #6, we have:\n",
    "\n",
    "* A total of `5749` unique persons in our dataset. `1680` people have multiple images, and `4068` people with only 1 image\n",
    "* A total of `13233` images, of which `9164` are part of the multiple images per person, and naturally `4068` solo images.\n",
    "\n",
    "Thinking in a way to reduce the chances of data leakage, or just to test the model's generalisability, perhaps it would be better to perform a train test split on the individual people, and not on an image level.\n",
    "\n",
    "If the end goal is a model that can perform one-shot facial verification on multiple people, the model should be able to perform well on many people, and so the evaluation of the model should involve assessing its performance on unseen people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, something to address with that methodology, is the fact that some people have more multiple images of themselves, so performing a split on unique persons without taking into account the number of images there are per person might not be the best way to go. \n",
    "\n",
    "As brought up in Issue #6, we can technically have many permutations of positive and negative labels just from matching different images together, which would increase our dataset. But let's still split them while taking into account the number of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Creating DF with Counts, and Separating the People with Unique Counts of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_counts = df['person'].value_counts().reset_index()\n",
    "person_counts.columns = ['person', 'num_photos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George_W_Bush</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colin_Powell</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tony_Blair</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald_Rumsfeld</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerhard_Schroeder</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              person  num_photos\n",
       "0      George_W_Bush         530\n",
       "1       Colin_Powell         236\n",
       "2         Tony_Blair         144\n",
       "3    Donald_Rumsfeld         121\n",
       "4  Gerhard_Schroeder         109"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One good way to split our dataset into train and test sets would be to make sure the proportion of photos per person is constant across the split. This might help the model to generalise to the test set a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's start by checking if there are any people with unique numbers of images in the dataset. We kind of already know that there are from the cell above, which shows 5 people with non repeating `num_photos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_photos\n",
       "530    1\n",
       "236    1\n",
       "144    1\n",
       "27     1\n",
       "25     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_photo_count= person_counts['num_photos'].value_counts()\n",
    "num_photo_count.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people whose count of images is unique: 18\n"
     ]
    }
   ],
   "source": [
    "unique_counts = []\n",
    "for num_photos, count in num_photo_count.items():\n",
    "    if count == 1:\n",
    "        unique_counts.append(num_photos)\n",
    "        \n",
    "print(f'Number of people whose count of images is unique: {len(unique_counts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Train Test Splitting the Datasets, Stratifying on Number of Photos per Person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 18 people whose count of images in unique. Let's extract them out of the dataset first and do a train test split on the rest. We'll do an 80 / 20 split. I am not going to split the datasets in to Train, test and validation as this is meant to be quick, small project, and I want to keep things simple for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nestor_Kirchner</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Andre_Agassi</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alvaro_Uribe</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ricardo_Lagos</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             person  num_photos\n",
       "21  Nestor_Kirchner          37\n",
       "22     Andre_Agassi          36\n",
       "23     Alvaro_Uribe          35\n",
       "38    Ricardo_Lagos          27\n",
       "41      Tom_Daschle          25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count_people = person_counts[person_counts['num_photos'].isin(unique_counts)]\n",
    "unique_count_people.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_counts = person_counts[~person_counts['person'].isin(unique_count_people['person'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5731"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_counts['person'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_persons, test_persons = train_test_split(person_counts, test_size=0.2, stratify=person_counts['num_photos'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4584, 1147)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_persons['person'].nunique(), test_persons['person'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4584 people in the train set, and 1147 people in the test set. Nice! Let's check the total number of images as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 9234, Number of testing images: 2242\n"
     ]
    }
   ],
   "source": [
    "num_train_images = train_persons.sum()['num_photos']\n",
    "num_test_images = test_persons.sum()['num_photos']\n",
    "\n",
    "print(f'Number of training images: {num_train_images}, Number of testing images: {num_test_images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty nice split so far. The next thing we can do is incorporate the people with unique image counts into the train and test set. For this, we can just manually assign them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Manually Assigning People with Unique Image Counts into Train or Test Set\n",
    "\n",
    "So far, we've done a train test split based on unique persons, and stratifying by the number of images. We have 18 people with unique counts, which is relatively few compared to the 4584 people in the train set and 1147 in the test. For these 18 people, let's take a slightly different approach and focus on splitting them by the number of images instead, since the range of the number of images is so wide (25 to 530). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of images of people with unique image counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1757)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count_people['num_photos'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we split the train and test set to 80 / 20, let's try and get to a similar ratio for the people with unique image counts as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images in training set: 1405.6000000000001, Number of unique images in testing set: 351.40000000000003\n"
     ]
    }
   ],
   "source": [
    "train_number = 0.8 * unique_count_people['num_photos'].sum()\n",
    "test_number = 0.2 * unique_count_people['num_photos'].sum()\n",
    "print(f'Number of unique images in training set: {train_number}, Number of unique images in testing set: {test_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George_W_Bush</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colin_Powell</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tony_Blair</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald_Rumsfeld</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerhard_Schroeder</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ariel_Sharon</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hugo_Chavez</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junichiro_Koizumi</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jean_Chretien</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>John_Ashcroft</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vladimir_Putin</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Luiz_Inacio_Lula_da_Silva</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gloria_Macapagal_Arroyo</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nestor_Kirchner</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Andre_Agassi</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alvaro_Uribe</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ricardo_Lagos</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       person  num_photos\n",
       "0               George_W_Bush         530\n",
       "1                Colin_Powell         236\n",
       "2                  Tony_Blair         144\n",
       "3             Donald_Rumsfeld         121\n",
       "4           Gerhard_Schroeder         109\n",
       "5                Ariel_Sharon          77\n",
       "6                 Hugo_Chavez          71\n",
       "7           Junichiro_Koizumi          60\n",
       "8               Jean_Chretien          55\n",
       "9               John_Ashcroft          53\n",
       "12             Vladimir_Putin          49\n",
       "13  Luiz_Inacio_Lula_da_Silva          48\n",
       "14    Gloria_Macapagal_Arroyo          44\n",
       "21            Nestor_Kirchner          37\n",
       "22               Andre_Agassi          36\n",
       "23               Alvaro_Uribe          35\n",
       "38              Ricardo_Lagos          27\n",
       "41                Tom_Daschle          25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person        John_AshcroftVladimir_PutinLuiz_Inacio_Lula_da...\n",
       "num_photos                                                  354\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count_people.tail(9).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, getting the last 9 people in the `unique_count_people` dataframe gets us a total of 354 images, not exactly 351, but that's fine of course. Now let's assign them to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.int64(1403), np.int64(354))\n"
     ]
    }
   ],
   "source": [
    "unique_test_people = unique_count_people.tail(9)\n",
    "unique_train_people = unique_count_people.drop(unique_test_people.index)\n",
    "print((unique_train_people['num_photos'].sum(), unique_test_people['num_photos'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.int64(12040), np.int64(2950))\n"
     ]
    }
   ],
   "source": [
    "train_persons = pd.concat([train_persons, unique_train_people])\n",
    "test_persons = pd.concat([test_persons, unique_test_people])\n",
    "\n",
    "print((train_persons['num_photos'].sum(), test_persons['num_photos'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we've successfully split our dataset into train and test sets in an 80/20 split. To make things easier, let's save these dataframes in parquet format for further issues, and let's also do some manipulation so that we have dataframes similar to the initial format, with the paths to the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_persons, df, on='person', how='left')\n",
    "test_df = pd.merge(test_persons, df, on='person', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alicia_Hollowell</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Alic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dwayne_Johnson</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Dway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwayne_Johnson</td>\n",
       "      <td>2</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Dway...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim_Doyle</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Jim_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pierre_Lacroix</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Pier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>Jean_Chretien</td>\n",
       "      <td>55</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Jean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12036</th>\n",
       "      <td>Jean_Chretien</td>\n",
       "      <td>55</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Jean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12037</th>\n",
       "      <td>Jean_Chretien</td>\n",
       "      <td>55</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Jean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12038</th>\n",
       "      <td>Jean_Chretien</td>\n",
       "      <td>55</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Jean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12039</th>\n",
       "      <td>Jean_Chretien</td>\n",
       "      <td>55</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Jean...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12040 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 person  num_photos  \\\n",
       "0      Alicia_Hollowell           1   \n",
       "1        Dwayne_Johnson           2   \n",
       "2        Dwayne_Johnson           2   \n",
       "3             Jim_Doyle           1   \n",
       "4        Pierre_Lacroix           1   \n",
       "...                 ...         ...   \n",
       "12035     Jean_Chretien          55   \n",
       "12036     Jean_Chretien          55   \n",
       "12037     Jean_Chretien          55   \n",
       "12038     Jean_Chretien          55   \n",
       "12039     Jean_Chretien          55   \n",
       "\n",
       "                                              image_path  \n",
       "0      ../data/lfw-deepfunneled/lfw-deepfunneled/Alic...  \n",
       "1      ../data/lfw-deepfunneled/lfw-deepfunneled/Dway...  \n",
       "2      ../data/lfw-deepfunneled/lfw-deepfunneled/Dway...  \n",
       "3      ../data/lfw-deepfunneled/lfw-deepfunneled/Jim_...  \n",
       "4      ../data/lfw-deepfunneled/lfw-deepfunneled/Pier...  \n",
       "...                                                  ...  \n",
       "12035  ../data/lfw-deepfunneled/lfw-deepfunneled/Jean...  \n",
       "12036  ../data/lfw-deepfunneled/lfw-deepfunneled/Jean...  \n",
       "12037  ../data/lfw-deepfunneled/lfw-deepfunneled/Jean...  \n",
       "12038  ../data/lfw-deepfunneled/lfw-deepfunneled/Jean...  \n",
       "12039  ../data/lfw-deepfunneled/lfw-deepfunneled/Jean...  \n",
       "\n",
       "[12040 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luis_Berrondo</td>\n",
       "      <td>1</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Luis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Antonio_Palocci</td>\n",
       "      <td>8</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonio_Palocci</td>\n",
       "      <td>8</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antonio_Palocci</td>\n",
       "      <td>8</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antonio_Palocci</td>\n",
       "      <td>8</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Anto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               person  num_photos  \\\n",
       "0       Luis_Berrondo           1   \n",
       "1     Antonio_Palocci           8   \n",
       "2     Antonio_Palocci           8   \n",
       "3     Antonio_Palocci           8   \n",
       "4     Antonio_Palocci           8   \n",
       "...               ...         ...   \n",
       "2945      Tom_Daschle          25   \n",
       "2946      Tom_Daschle          25   \n",
       "2947      Tom_Daschle          25   \n",
       "2948      Tom_Daschle          25   \n",
       "2949      Tom_Daschle          25   \n",
       "\n",
       "                                             image_path  \n",
       "0     ../data/lfw-deepfunneled/lfw-deepfunneled/Luis...  \n",
       "1     ../data/lfw-deepfunneled/lfw-deepfunneled/Anto...  \n",
       "2     ../data/lfw-deepfunneled/lfw-deepfunneled/Anto...  \n",
       "3     ../data/lfw-deepfunneled/lfw-deepfunneled/Anto...  \n",
       "4     ../data/lfw-deepfunneled/lfw-deepfunneled/Anto...  \n",
       "...                                                 ...  \n",
       "2945  ../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...  \n",
       "2946  ../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...  \n",
       "2947  ../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...  \n",
       "2948  ../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...  \n",
       "2949  ../data/lfw-deepfunneled/lfw-deepfunneled/Tom_...  \n",
       "\n",
       "[2950 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet('../data/train.parquet')\n",
    "test_df.to_parquet('../data/test.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siamese-nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
