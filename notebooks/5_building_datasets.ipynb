{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Datasets For Model Training\n",
    "\n",
    "Carrying on from [Issue #6](https://github.com/dannylyl/siamese-nn-facial-recognition/issues/6), this issue will involve steps for building the datasets for further downstream steps in this project. This would include:\n",
    "\n",
    "1. Deciding Train Test Split Methodology and Implementation\n",
    "2. Building Positive (similar) and Negative (dissimilar) pairs and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting Pandas DF of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the notebook for issue #6, I will start by first organising the data into a pandas dataframe (personal preference I guess since I usually work with data in DFs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/lfw-deepfunneled/lfw-deepfunneled'\n",
    "\n",
    "data = []\n",
    "\n",
    "for person in os.listdir(data_dir):\n",
    "    person_dir = os.path.join(data_dir, person)\n",
    "    if os.path.isdir(person_dir):\n",
    "        for image in os.listdir(person_dir):\n",
    "            data.append((os.path.join(person_dir, image), person))\n",
    "            \n",
    "df = pd.DataFrame(data, columns=['image_path', 'person'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Alic...</td>\n",
       "      <td>Alice_Fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Alic...</td>\n",
       "      <td>Alice_Fisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Elle...</td>\n",
       "      <td>Ellen_Barkin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Quee...</td>\n",
       "      <td>Queen_Latifah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/lfw-deepfunneled/lfw-deepfunneled/Quee...</td>\n",
       "      <td>Queen_Latifah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path         person\n",
       "0  ../data/lfw-deepfunneled/lfw-deepfunneled/Alic...   Alice_Fisher\n",
       "1  ../data/lfw-deepfunneled/lfw-deepfunneled/Alic...   Alice_Fisher\n",
       "2  ../data/lfw-deepfunneled/lfw-deepfunneled/Elle...   Ellen_Barkin\n",
       "3  ../data/lfw-deepfunneled/lfw-deepfunneled/Quee...  Queen_Latifah\n",
       "4  ../data/lfw-deepfunneled/lfw-deepfunneled/Quee...  Queen_Latifah"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Test Split Methodology\n",
    "\n",
    "As suggested from Issue #6, we have:\n",
    "\n",
    "* A total of `5749` unique persons in our dataset. `1680` people have multiple images, and `4068` people with only 1 image\n",
    "* A total of `13233` images, of which `9164` are part of the multiple images per person, and naturally `4068` solo images.\n",
    "\n",
    "Thinking in a way to reduce the chances of data leakage, or just to test the model's generalisability, perhaps it would be better to perform a train test split on the individual people, and not on an image level.\n",
    "\n",
    "If the end goal is a model that can perform one-shot facial verification on multiple people, the model should be able to perform well on many people, and so the evaluation of the model should involve assessing its performance on unseen people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, something to address with that methodology, is the fact that some people have more multiple images of themselves, so performing a split on unique persons without taking into account the number of images there are per person might not be the best way to go. \n",
    "\n",
    "As brought up in Issue #6, we can technically have many permutations of positive and negative labels just from matching different images together, which would increase our dataset. But let's still split them while taking into account the number of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Creating DF with Counts, and Separating the People with Unique Counts of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_counts = df['person'].value_counts().reset_index()\n",
    "person_counts.columns = ['person', 'num_photos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George_W_Bush</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Colin_Powell</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tony_Blair</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald_Rumsfeld</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gerhard_Schroeder</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              person  num_photos\n",
       "0      George_W_Bush         530\n",
       "1       Colin_Powell         236\n",
       "2         Tony_Blair         144\n",
       "3    Donald_Rumsfeld         121\n",
       "4  Gerhard_Schroeder         109"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One good way to split our dataset into train and test sets would be to make sure the proportion of photos per person is constant across the split. This might help the model to generalise to the test set a bit better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's start by checking if there are any people with unique numbers of images in the dataset. We kind of already know that there are from the cell above, which shows 5 people with non repeating `num_photos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_photos\n",
       "530    1\n",
       "236    1\n",
       "144    1\n",
       "27     1\n",
       "25     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_photo_count= person_counts['num_photos'].value_counts()\n",
    "num_photo_count.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people whose count of images is unique: 18\n"
     ]
    }
   ],
   "source": [
    "unique_counts = []\n",
    "for num_photos, count in num_photo_count.items():\n",
    "    if count == 1:\n",
    "        unique_counts.append(num_photos)\n",
    "        \n",
    "print(f'Number of people whose count of images is unique: {len(unique_counts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Train Test Splitting the Datasets, Stratifying on Number of Photos per Person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 18 people whose count of images in unique. Let's extract them out of the dataset first and do a train test split on the rest. We'll do an 80 / 20 split. I am not going to split the datasets in to Train, test and validation as this is meant to be quick, small project, and I want to keep things simple for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>num_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nestor_Kirchner</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Andre_Agassi</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Alvaro_Uribe</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ricardo_Lagos</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tom_Daschle</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             person  num_photos\n",
       "21  Nestor_Kirchner          37\n",
       "22     Andre_Agassi          36\n",
       "23     Alvaro_Uribe          35\n",
       "38    Ricardo_Lagos          27\n",
       "41      Tom_Daschle          25"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count_people = person_counts[person_counts['num_photos'].isin(unique_counts)]\n",
    "unique_count_people.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_counts = person_counts[~person_counts['person'].isin(unique_count_people['person'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5731"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_counts['person'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_persons, test_persons = train_test_split(person_counts, test_size=0.2, stratify=person_counts['num_photos'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4584, 1147)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_persons['person'].nunique(), test_persons['person'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4584 people in the train set, and 1147 people in the test set. Nice! Let's check the total number of images as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 9234, Number of testing images: 2242\n"
     ]
    }
   ],
   "source": [
    "num_train_images = train_persons.sum()['num_photos']\n",
    "num_test_images = test_persons.sum()['num_photos']\n",
    "\n",
    "print(f'Number of training images: {num_train_images}, Number of testing images: {num_test_images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty nice split so far. The next thing we can do is incorporate the people with unique image counts into the train and test set. For this, we can just manually assign them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Manually Assigning People with Unique Image Counts into Train or Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siamese-nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
